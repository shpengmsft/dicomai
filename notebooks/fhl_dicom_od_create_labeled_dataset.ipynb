{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0eadf4def0511d16cff3b403ebad030b79626359e624f736446cdd8402c7991c1",
   "display_name": "Python 3.8.10 64-bit ('fhl_py38': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Create BoundingBox Labeled Datasets from CSV ground truth\n",
    "\n",
    "\n",
    "This script will create two labeled datasets: <dataset_name>_training and <dataset_name>_test\n",
    "\n",
    "1. split training and test labeled datapoints\n",
    "2. create jason-line files for training and test\n",
    "3. upload jason-line files to default workspace blobstore, under fhl/datasets/<dataset_name>/label folder\n",
    "4. register labeled datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = 'workspaceblobstore'\n",
    "dataset_name = 'NoWindowOD_FullNegtive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ground truth from csv file\n",
    "raw_df = pd.read_csv('./labels/stage_2_train_labels.csv')\n",
    "\n",
    "# adding label\n",
    "def get_label(row):\n",
    "    if row['Target']  == 0:\n",
    "        val = 'Not Lung Opacity'\n",
    "    elif row['Target'] == 1:\n",
    "        val = 'Lung Opacity'\n",
    "    return val\n",
    "raw_df['Label'] =  raw_df.apply(get_label, axis=1)\n",
    "\n",
    "# Filling NaN with average values\n",
    "#raw_df['x'].fillna(value=raw_df['x'].mean(), inplace=True)\n",
    "#raw_df['y'].fillna(value=raw_df['y'].mean(), inplace=True)\n",
    "#raw_df['width'].fillna(value=raw_df['width'].mean(), inplace=True)\n",
    "#raw_df['height'].fillna(value=raw_df['height'].mean(), inplace=True)\n",
    "\n",
    "# Filling NaN with average values\n",
    "raw_df['x'].fillna(value=0, inplace=True)\n",
    "raw_df['y'].fillna(value=0, inplace=True)\n",
    "raw_df['width'].fillna(value=1024, inplace=True)\n",
    "raw_df['height'].fillna(value=1024, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge by\n",
    "IMG_WIDTH = 1024\n",
    "IMG_HEIGHT = 1024\n",
    "jsonline_obj = []\n",
    "tags = []\n",
    "target_count = 0\n",
    "for patient_id in raw_df['patientId'].unique():\n",
    "    obj = {}\n",
    "    target = False\n",
    "    obj['image_url'] = 'AmlDatastore://' + datastore_name + '/fhl/datasets/' + dataset_name + '/image/' + patient_id + '.png'\n",
    "    obj['label'] = []\n",
    "    obj['label_confidence'] = []\n",
    "    sub_df = raw_df[raw_df['patientId'] == patient_id]\n",
    "    for _, row in sub_df.iterrows():\n",
    "        target = row['Label'] == 'Lung Opacity'\n",
    "        label = {'label': row['Label'], 'topX': row['x']/IMG_WIDTH, 'topY': row['y']/IMG_HEIGHT, 'bottomX': (row['x'] + row['width'])/IMG_WIDTH, 'bottomY': (row['y'] + row['height'])/IMG_HEIGHT}\n",
    "        obj['label'].append(label)\n",
    "        obj['label_confidence'].append(1.0)\n",
    "    jsonline_obj.append(obj)\n",
    "    if target:\n",
    "        tags.append('Lung Opacity')\n",
    "        target_count += 1\n",
    "    else:\n",
    "        tags.append('Not Lung Opacity')\n",
    "image_df = pd.DataFrame({'obj':jsonline_obj,'tag':tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Not Lung Opacity    20672\n",
       "Lung Opacity         6012\n",
       "Name: tag, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "image_df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Not Lung Opacity    4848\n",
       "Lung Opacity        4771\n",
       "Name: tag, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#  Down-sample Not Lung Opacit\n",
    "from sklearn.utils import resample\n",
    "major_df = image_df[image_df['tag'] == 'Not Lung Opacity']\n",
    "minor_df = image_df[image_df['tag'] == 'Lung Opacity']\n",
    "down_sample_df = resample(major_df, replace=False, n_samples=minor_df.shape[0])\n",
    "source_df = pd.concat([down_sample_df, minor_df])\n",
    "train, test = train_test_split(source_df, test_size = 0.2, random_state = 2021)\n",
    "train['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj = train['obj']\n",
    "test_obj = test['obj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "def save_jasonline_file(objects: list, file_name: str):\n",
    "    base_path = os.path.dirname(file_name)\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "    with open(file_name, 'w') as jf:\n",
    "        for obj in objects:\n",
    "            jf.write('{}\\n'.format(json.dumps(obj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate jsonline files, which can be registered as labeled dataset\n",
    "label_folder = os.path.abspath(os.path.join(os.path.curdir, 'label'))\n",
    "save_jasonline_file(train_obj, os.path.join(label_folder, 'labeleddatapoints_training.jsonl'))\n",
    "save_jasonline_file(test_obj, os.path.join(label_folder, 'labeleddatapoints_test.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-core 1.18.0.post4 (c:\\users\\shpeng\\appdata\\roaming\\python\\python38\\site-packages), Requirement.parse('azureml-core~=1.29.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-core 1.18.0.post4 (c:\\users\\shpeng\\appdata\\roaming\\python\\python38\\site-packages), Requirement.parse('azureml-core~=1.29.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.18.0.post4 (c:\\users\\shpeng\\appdata\\roaming\\python\\python38\\site-packages), Requirement.parse('azureml-core~=1.29.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.18.0.post4 (c:\\users\\shpeng\\appdata\\roaming\\python\\python38\\site-packages), Requirement.parse('azureml-core~=1.29.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.18.0.post4 (c:\\users\\shpeng\\appdata\\roaming\\python\\python38\\site-packages), Requirement.parse('azureml-core~=1.29.0')).\n",
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
      "Uploading an estimated of 2 files\n",
      "Uploading c:\\gitroot\\dicomai\\notebooks\\label\\labeleddatapoints_test.jsonl\n",
      "Uploaded c:\\gitroot\\dicomai\\notebooks\\label\\labeleddatapoints_test.jsonl, 1 files out of an estimated total of 2\n",
      "Uploading c:\\gitroot\\dicomai\\notebooks\\label\\labeleddatapoints_training.jsonl\n",
      "Uploaded c:\\gitroot\\dicomai\\notebooks\\label\\labeleddatapoints_training.jsonl, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_5069bc6a72954c7fbfa516b3fd48ece4"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "# Load workspace\n",
    "ws = Workspace.from_config()\n",
    "ds = ws.datastores['workspaceblobstore']\n",
    "ds.upload(src_dir = label_folder, target_path= '/fhl/datasets/' + dataset_name + '/label/', overwrite= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'fhl/datasets/NoWindowOD_FullNegtive/label/labeleddatapoints_test.jsonl')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseJsonLines\",\n",
       "    \"ExpressionAddColumn\",\n",
       "    \"DropColumns\",\n",
       "    \"DropColumns\",\n",
       "    \"RenameColumns\",\n",
       "    \"DropColumns\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"dce6cec0-1d1e-449e-9248-1bfd9fd29271\",\n",
       "    \"name\": \"NoWindowOD_FullNegtive_test\",\n",
       "    \"version\": 1,\n",
       "    \"tags\": {\n",
       "      \"labelingCreatedBy\": \"FHL Notebook\",\n",
       "      \"labelingProjectType\": \"Object Identification (Bounding Box)\",\n",
       "      \"SourceDatastoreName\": \"workspaceblobstore\",\n",
       "      \"SourceRelativePath\": \"fhl/datasets/NoWindowOD_FullNegtive/image/\",\n",
       "      \"labelingLabelName\": \"[\\\"Lung Opacity\\\",\\\"No Lung Opacity\\\"]\"\n",
       "    },\n",
       "    \"workspace\": \"Workspace.create(name='DICOMmodel', subscription_id='f375b912-331c-4fc5-8e9f-2d7205e3e036', resource_group='dicom-model-rg')\"\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Create/register labeled dataset for training and test(inference)\n",
    "from azureml.contrib.dataset.labeled_dataset import _LabeledDatasetFactory, LabeledDatasetTask\n",
    "\n",
    "tags = {}\n",
    "tags['labelingCreatedBy'] = \"FHL Notebook\"\n",
    "tags['labelingProjectType'] = 'Object Identification (Bounding Box)'\n",
    "tags['SourceDatastoreName'] = 'workspaceblobstore'\n",
    "tags['SourceRelativePath'] = 'fhl/datasets/' + dataset_name + '/image/'\n",
    "tags['labelingLabelName'] = '[\"Lung Opacity\",\"No Lung Opacity\"]'\n",
    "\n",
    "training_dataset = _LabeledDatasetFactory.from_json_lines(task=LabeledDatasetTask.IMAGE_CLASSIFICATION, path=ds.path('fhl/datasets/' + dataset_name + '/label/labeleddatapoints_training.jsonl'))\n",
    "training_dataset.register(ws, dataset_name + '_training', tags= tags)\n",
    "\n",
    "test_dataset = _LabeledDatasetFactory.from_json_lines(task=LabeledDatasetTask.IMAGE_CLASSIFICATION, path=ds.path('fhl/datasets/' + dataset_name + '/label/labeleddatapoints_test.jsonl'))\n",
    "test_dataset.register(ws, dataset_name + '_test', tags= tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}