{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0eadf4def0511d16cff3b403ebad030b79626359e624f736446cdd8402c7991c1",
   "display_name": "Python 3.8.10 64-bit ('fhl_py38': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Create JasonLine files from CSV ground truth\n",
    "\n",
    "\n",
    "This script will create two labeled datasets: <dataset_name>_training and <dataset_name>_test\n",
    "\n",
    "1. split training and test labeled datapoints\n",
    "2. create jason-line files for training and test\n",
    "3. upload jason-line files to default workspace blobstore, under fhl/datasets/<dataset_name>/label folder\n",
    "4. register labeled datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = 'workspaceblobstore'\n",
    "dataset_name = 'NoWindow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ground truth from csv file\n",
    "raw_df = pd.read_csv('./labels/stage_2_detailed_class_info.csv')\n",
    "dedup_df = raw_df[ (raw_df['patientId'].duplicated(keep='first') == False)]\n",
    "train, test = train_test_split(dedup_df, test_size = 0.2, random_state = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Multi-Class JasonLine Objects\n",
    "def create_jasonline_objects(datastore_name: str, dataset_name: str, df: pd.DataFrame):\n",
    "    jsonline_obj = []\n",
    "    for _, row in df.iterrows():\n",
    "        obj = {}\n",
    "        obj['image_url'] = 'AmlDatastore://' + datastore_name + '/fhl/datasets/' + dataset_name + '/image/' + row['patientId'] + '.png'\n",
    "        obj['label'] = row['class']\n",
    "        obj['label_confidence'] = 1.0\n",
    "        jsonline_obj.append(obj)\n",
    "    return jsonline_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "def save_jasonline_file(objects: list, file_name: str):\n",
    "    base_path = os.path.dirname(file_name)\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "    with open(file_name, 'w') as jf:\n",
    "        for obj in objects:\n",
    "            jf.write('{}\\n'.format(json.dumps(obj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate jsonline files, which can be registered as labeled dataset\n",
    "training_label_folder = os.path.abspath(os.path.join(os.path.curdir, 'training_label'))\n",
    "test_label_folder = os.path.abspath(os.path.join(os.path.curdir, 'test_label'))\n",
    "\n",
    "train_obj = create_jasonline_objects(datastore_name, dataset_name, train)\n",
    "save_jasonline_file(train_obj, os.path.join(training_label_folder, 'labeleddatapoints_training.jsonl'))\n",
    "\n",
    "test_obj = create_jasonline_objects(datastore_name, dataset_name, test)\n",
    "save_jasonline_file(test_obj, os.path.join(test_label_folder, 'labeleddatapoints_test.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "# Load workspace\n",
    "ws = Workspace.from_config()\n",
    "ds = ws.datastores['workspaceblobstore']\n",
    "ds.upload(src_dir = training_label_folder, target_path= '/fhl/datasets/' + dataset_name + '/label/', overwrite= True)\n",
    "ds.upload(src_dir = './test_label', target_path= '/fhl/datasets/' + dataset_name + '/label/', overwrite= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/register labeled dataset for training and test(inference)\n",
    "from azureml.contrib.dataset.labeled_dataset import _LabeledDatasetFactory, LabeledDatasetTask\n",
    "\n",
    "tags = {}\n",
    "tags['labelingCreatedBy'] = \"Guess\"\n",
    "tags['labelingProjectType'] = 'Image Classification Multi-class'\n",
    "tags['SourceDatastoreName'] = 'workspaceblobstore'\n",
    "tags['SourceRelativePath'] = 'fhl/datasets/' + dataset_name + '/image/'\n",
    "tags['labelingLabelName'] = '[\"Lung Opacity\",\"No Lung Opacity / Not Normal\",\"Normal\"]'\n",
    "\n",
    "training_dataset = _LabeledDatasetFactory.from_json_lines(task=LabeledDatasetTask.IMAGE_CLASSIFICATION, path=ds.path('fhl/datasets/' + dataset_name + '/label/labeleddatapoints_training.jsonl'))\n",
    "training_dataset.register(ws, dataset_name + '_training', tags= tags)\n",
    "\n",
    "test_dataset = _LabeledDatasetFactory.from_json_lines(task=LabeledDatasetTask.IMAGE_CLASSIFICATION, path=ds.path('fhl/datasets/' + dataset_name + '/label/labeleddatapoints_test.jsonl'))\n",
    "test_dataset.register(ws, dataset_name + '_test', tags= tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}