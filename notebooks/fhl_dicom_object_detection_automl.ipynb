{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/ignore-notebook)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Run, Workspace\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "import azureml.dataprep as dprep\n",
        "from azureml.core.dataset import Dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172267411
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load workspace\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172268487
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for the run history container in the workspace.\n",
        "experiment_name = 'NoWindowOD'\n",
        "project_folder = './project'\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "\n",
        "output = {}\n",
        "output['SDK version'] = azureml.core.VERSION\n",
        "output['Subscription ID'] = ws.subscription_id\n",
        "output['Workspace Name'] = ws.name\n",
        "output['Resource Group'] = ws.resource_group\n",
        "output['Location'] = ws.location\n",
        "output['Project Directory'] = project_folder\n",
        "output['Experiment Name'] = experiment.name\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "outputDf = pd.DataFrame(data = output, index = [''])\n",
        "outputDf.T"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172269397
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "\n",
        "# Choose a name for your cluster.\n",
        "amlcompute_cluster_name = \"gpu-cluster\"\n",
        "\n",
        "found = False\n",
        "# Check if this compute target already exists in the workspace.\n",
        "cts = ws.compute_targets\n",
        "compute_target = None\n",
        "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
        "    found = True\n",
        "    print('Found existing compute target.')\n",
        "    compute_target = cts[amlcompute_cluster_name]\n",
        "\n",
        "if not found:\n",
        "    print('Creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
        "                                                                max_nodes = 4)\n",
        "    # Create the cluster.\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
        "\n",
        "# Can poll for a minimum number of nodes and for a specific timeout.\n",
        "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
        "compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
        "\n",
        "# For a more detailed view of current AmlCompute status, use get_status()."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172270106
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.datastore import Datastore\n",
        "\n",
        "# replace with account key for visionnotebooksdata storage account\n",
        "from azureml.core.datastore import Datastore\n",
        "if 'datasets' in ws.datastores.keys():\n",
        "    ds = ws.datastores['datasets']\n",
        "else:\n",
        "    account_key = os.getenv(\"ACCOUNT_KEY\")\n",
        "    ds = Datastore.register_azure_blob_container(ws, datastore_name='datasets', container_name='imagecontainer', \n",
        "                                             account_name='dicommodel2290602728', account_key=account_key, \n",
        "                                             resource_group='dicom-model-rg')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172270646
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.contrib.dataset.labeled_dataset import _LabeledDatasetFactory, LabeledDatasetTask\n",
        "from azureml.core import Dataset\n",
        "\n",
        "# get training dataset\n",
        "training_dataset_name = experiment_name + \"_training\"\n",
        "if training_dataset_name in ws.datasets:\n",
        "    training_dataset = ws.datasets.get(training_dataset_name)\n",
        "    print('Found the training dataset', training_dataset_name)\n",
        "else:\n",
        "    raise RuntimeError('Please use fhl_dicom_multiclass_create_labeled_datasets.ipynb to create labeled dataset for training.')\n",
        "\n",
        "print(\"Training dataset name: \" + training_dataset.name)\n",
        "\n",
        "# get test dataset\n",
        "test_dataset_name = experiment_name + \"_test\"\n",
        "if test_dataset_name in ws.datasets:\n",
        "    test_dataset = ws.datasets.get(test_dataset_name)\n",
        "    print('Found the test dataset', test_dataset_name)\n",
        "else:\n",
        "    raise RuntimeError('Please use fhl_dicom_multiclass_create_labeled_datasets.ipynb to create labeled dataset for training.')\n",
        "\n",
        "    \n",
        "print(\"Training dataset name: \" + training_dataset.name)\n",
        "print(\"Test dataset name: \" + test_dataset_name)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172273457
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_settings = {\n",
        "    \"deterministic\": True,\n",
        "    \"enable_dnn\": True,\n",
        "    \"featurization\": \"off\",\n",
        "    \"iteration_timeout_minutes\": 1000,\n",
        "    \"iterations\": 1,\n",
        "    \"log_verbose_metrics\": True,\n",
        "    \"primary_metric\": \"mean_average_precision\",\n",
        "    \"print_local_package_versions\": True,\n",
        "    \"seed\" : 47\n",
        "}\n",
        "\n",
        "if os.getenv(\"SCENARIO\"):\n",
        "    automl_settings[\"scenario\"] = os.getenv(\"SCENARIO\")\n",
        "\n",
        "automl_config = AutoMLConfig(task = 'image-object-detection',\n",
        "                             debug_log = 'automl_errors_1.log',\n",
        "                             path = project_folder,\n",
        "                             compute_target=compute_target,\n",
        "                             training_data=training_dataset,\n",
        "                             # validation_data=validation_dataset,\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172273826
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remote_run = experiment.submit(automl_config, show_output = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172279642
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remote_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622172280083
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remote_run.wait_for_completion(wait_post_processing=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622228591435
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference runs"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "from azureml.core.script_run_config import ScriptRunConfig"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622228591560
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training script run corresponding to AutoML run above.\n",
        "training_run_id = remote_run.id + \"_HD_0\"\n",
        "training_run = Run(experiment, training_run_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622228591877
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference script run arguments\n",
        "arguments = [\n",
        "        \"--run_id\", training_run_id,\n",
        "        \"--experiment_name\", experiment.name,\n",
        "        \"--input_dataset_id\", test_dataset.id,\n",
        "        \"--validate_score\", True\n",
        "    \n",
        "    ]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622228592019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scoring run"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "output_prediction_file = \"./outputs/predictions.txt\"\n",
        "scoring_args = arguments + [\"--output_file\", output_prediction_file]\n",
        "with tempfile.TemporaryDirectory() as tmpdir:\n",
        "    # Download required files from training run into temp folder.\n",
        "    entry_script_name = \"score_script.py\"\n",
        "    output_path = os.path.join(tmpdir, entry_script_name)\n",
        "    training_run.download_file(\"train_artifacts/\" + entry_script_name, os.path.join(tmpdir, entry_script_name))\n",
        "    \n",
        "    script_run_config = ScriptRunConfig(source_directory=tmpdir,\n",
        "                                        script=entry_script_name,\n",
        "                                        compute_target=compute_target,\n",
        "                                        environment=training_run.get_environment(),\n",
        "                                        arguments=scoring_args)\n",
        "    scoring_run = experiment.submit(script_run_config)  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622228596737
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoring_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622228597018
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoring_run.wait_for_completion(wait_post_processing=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1622240282685
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Prediction Results"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoring_run.download_file(output_prediction_file, output_file_path=output_prediction_file)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1622240473503
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "automlimage"
      }
    ],
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}